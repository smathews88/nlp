{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxhyQI9o1Zo7Y+4SAtq/Ax",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smathews88/nlp/blob/main/03_NLP_LLM_Embedding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Understanding the Difference Between Embedding Layers and Linear Layers**"
      ],
      "metadata": {
        "id": "5LijGn-U2KlV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using nn.Embedding**"
      ],
      "metadata": {
        "id": "5yfug_euKoei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch;\n",
        "#suppose 2, 3, 1 are the tokens generated after tokenizing..\n",
        "idx = torch.tensor([2, 3, 1])\n",
        "# The number of rows in the embedding matrix can be determined by obtaining the largest token ID + 1.\n",
        "num_idx = max(idx)+1\n",
        "# The desired embedding dimension is a hyperparameter\n",
        "out_dim = 5\n",
        "\n",
        "#below is a simple embedding layer\n",
        "torch.manual_seed(42)\n",
        "embedding = torch.nn.Embedding(num_idx, out_dim)\n",
        "\n",
        "embedding.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFhh9aSLKqRF",
        "outputId": "b6fc7f28-34b1-44f0-dc0a-f4ff6ce9aedc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.9269,  1.4873,  0.9007, -2.1055, -0.7581],\n",
              "        [ 1.0783,  0.8008,  1.6806,  0.3559, -0.6866],\n",
              "        [-0.4934,  0.2415, -0.2316,  0.0418, -0.2516],\n",
              "        [ 0.8599, -0.3097, -0.3957,  0.8034, -0.6216]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#below is the vector representation of training example with ID 1\n",
        "embedding(torch.tensor(idx))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDcrKSIKL2Kl",
        "outputId": "5fb82bc0-fa30-44a8-a705-ae30bc3763ae"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-73c7381ee1a6>:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  embedding(torch.tensor(idx))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4934,  0.2415, -0.2316,  0.0418, -0.2516],\n",
              "        [ 0.8599, -0.3097, -0.3957,  0.8034, -0.6216],\n",
              "        [ 1.0783,  0.8008,  1.6806,  0.3559, -0.6866]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using nn.Linear**"
      ],
      "metadata": {
        "id": "dpTQbUaVMnfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert token IDs into one hot encoding\n",
        "onehot = torch.nn.functional.one_hot(idx)\n",
        "onehot"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b4_eWC9MpqE",
        "outputId": "47c5dc70-bfff-4f1d-c234-302ab9cb8856"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 1, 0],\n",
              "        [0, 0, 0, 1],\n",
              "        [0, 1, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)\n",
        "linear = torch.nn.Linear(num_idx, out_dim, bias=False)\n",
        "linear.weight = torch.nn.Parameter(embedding.weight.T.detach())\n",
        "linear.weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di1jTL9CM9eY",
        "outputId": "4128847c-eb33-4202-eec2-ad74e9c402f3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([[ 1.9269,  1.0783, -0.4934,  0.8599],\n",
              "        [ 1.4873,  0.8008,  0.2415, -0.3097],\n",
              "        [ 0.9007,  1.6806, -0.2316, -0.3957],\n",
              "        [-2.1055,  0.3559,  0.0418,  0.8034],\n",
              "        [-0.7581, -0.6866, -0.2516, -0.6216]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#applying matmul\n",
        "linear(onehot.float())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjYzRtugOIHb",
        "outputId": "f88ea1a7-2254-4ced-9c87-9f4f0bb10fa4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.4934,  0.2415, -0.2316,  0.0418, -0.2516],\n",
              "        [ 0.8599, -0.3097, -0.3957,  0.8034, -0.6216],\n",
              "        [ 1.0783,  0.8008,  1.6806,  0.3559, -0.6866]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}