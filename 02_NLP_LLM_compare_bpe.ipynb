{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1QHZArFxwNh7oEY6d3lk_o9C9F8hsyq9v",
      "authorship_tag": "ABX9TyO9vwWsa6OpGERjV3gwbr4H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smathews88/nlp/blob/main/02_NLP_LLM_compare_bpe.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Downloading data**"
      ],
      "metadata": {
        "id": "hq7ctaSmCkTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import urllib.request\n",
        "url = (\"https://storage.googleapis.com/kagglesdsdata/datasets/701505/1226200/business/business_11.txt?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240618%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240618T074023Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=2a50233309ae50fdbceb07316abeca396bb3cba5cad1be5ef8517835b5a816738390e6ffe16f1bbc74b15811346339ea74135f03d565abdce9435c915ec7d10724d38432ed3135cb95744a088aa7557ae2f636f85e95ac8c3419fb63ea3b75222587206f0625b7f54c85ca3141597f4e641dd69348c6a8944849fe256a2248379c60f797100555cefdd3cf0fe735a5fed0d54df4638b4af0b7901089a685d3ef9c707d2fd9c406ccce1df5596402b1b0173b72201f7a6caf298cc001e7b26aa2d5adf4163ebadbf6935077e76c1c76720fc6936a4c295e0ad0ec59b842549e451ab6e79450f7c07bf05923a640f51759ffd77adfca2df10ac3ab8b03d229808b\")\n",
        "file_path = \"/content/drive/MyDrive/Colab Notebooks/dataset/business_11.txt\"\n",
        "urllib.request.urlretrieve(url, file_path)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/dataset/business_11.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    raw_text = f.read()"
      ],
      "metadata": {
        "id": "0qFlU7OHCo1D"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using BPE from tiktoken**\n",
        "\n",
        "Encodings specify how text is converted into tokens. Different models use different encodings.\n",
        "\n",
        "tiktoken supports three encodings used by OpenAI models"
      ],
      "metadata": {
        "id": "wVdIAR5yCLGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"gpt2\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"text-embedding-ada-002\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"text-embedding-3-small\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"text-embedding-3-large\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"text-davinci-002\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"text-davinci-003\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)\n",
        "tik_tokenizer = tiktoken.encoding_for_model(\"davinci\")\n",
        "%timeit tik_tokenizer.encode(raw_text)\n",
        "print(tik_tokenizer.n_vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sc2QWRKPCPjT",
        "outputId": "37459df1-959a-4209-fdfb-555401733624"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "916 µs ± 70.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "50257\n",
            "570 µs ± 9.55 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "100277\n",
            "579 µs ± 16.3 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "100277\n",
            "887 µs ± 228 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "100277\n",
            "565 µs ± 8.63 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "100277\n",
            "649 µs ± 172 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "100277\n",
            "634 µs ± 200 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "50281\n",
            "474 µs ± 8.72 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "50281\n",
            "729 µs ± 207 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n",
            "50257\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Using the BPE implementation used in HuggingFace**"
      ],
      "metadata": {
        "id": "BmYrjPFWDyhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "\n",
        "transformers.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "FMW0PltTD0eY",
        "outputId": "f7379767-f05e-4c97-9d08-2c22b3251c86"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'4.41.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, GPTSw3Tokenizer\n",
        "\n",
        "hf_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "%timeit hf_tokenizer(raw_text)\n",
        "print(hf_tokenizer.vocab_size)\n",
        "hf_tokenizer = GPT2Tokenizer.from_pretrained(\"Xenova/gpt-3.5-turbo\")\n",
        "%timeit hf_tokenizer(raw_text)\n",
        "print(hf_tokenizer.vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4Rmu3KDEVGp",
        "outputId": "c11edc0b-eeab-4df4-bc98-e15888e9d217"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.29 ms ± 217 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "50257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7.87 ms ± 227 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
            "100261\n"
          ]
        }
      ]
    }
  ]
}